import torch
import clip
import torch.nn.functional as F
from PIL import Image
import logging
import time
from app.utils.places import places

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)

class PlaceTagger:
    def __init__(self, model_name="ViT-L/14", threshold=0.4):
        try:
            logger.info(f"ğŸ”§ PlaceTagger ì´ˆê¸°í™” ì‹œì‘ (model: {model_name}, threshold: {threshold})")
            self.model_name = model_name
            self.threshold = threshold
            
            # GPU ì„¤ì • ë° ê²€ì¦
            if torch.backends.mps.is_available():
                self.device = torch.device("mps")
                logger.info("âœ… MPS ì‚¬ìš© ê°€ëŠ¥: Apple Silicon GPU ì‚¬ìš©")
            else:
                self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
                logger.info(f"âš ï¸ MPS ì‚¬ìš© ë¶ˆê°€: {self.device} ì‚¬ìš©")
            
            # CLIP ëª¨ë¸ ë¡œë“œ
            start_time = time.time()
            self.model, self.preprocess = clip.load(model_name, self.device)
            load_time = time.time() - start_time
            logger.info(f"âœ… CLIP ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (ì†Œìš”ì‹œê°„: {load_time:.2f}ì´ˆ)")
            
            # í”„ë¡¬í”„íŠ¸ ìˆ˜ì • - outdoor scene ì œê±°
            self.prompt_template = "a photo of {}"  # ë” ì¼ë°˜ì ì¸ í”„ë¡¬í”„íŠ¸ë¡œ ë³€ê²½
            self.labels = [self.prompt_template.format(place) for place in places.keys()]
            logger.info(f"âœ… í”„ë¡¬í”„íŠ¸ ì„¤ì • ì™„ë£Œ (ë ˆì´ë¸” ìˆ˜: {len(self.labels)}ê°œ)")
            
        except Exception as e:
            logger.error(f"âŒ PlaceTagger ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}", exc_info=True)
            raise

    def _validate_image(self, image):
        """ì´ë¯¸ì§€ ìœ íš¨ì„± ê²€ì‚¬ ë° ì „ì²˜ë¦¬"""
        if image is None:
            raise ValueError("ì´ë¯¸ì§€ê°€ Noneì…ë‹ˆë‹¤")
        
        # ì´ë¯¸ì§€ ëª¨ë“œ ê²€ì‚¬
        if image.mode != 'RGB':
            logger.info(f"âš ï¸ ì´ë¯¸ì§€ ëª¨ë“œ ë³€í™˜: {image.mode} â†’ RGB")
            image = image.convert('RGB')
        
        # ì´ë¯¸ì§€ í¬ê¸° ê²€ì‚¬
        min_size = 224
        original_size = image.size
        if image.size[0] < min_size or image.size[1] < min_size:
            logger.warning(f"âš ï¸ ì´ë¯¸ì§€ í¬ê¸°ê°€ ë„ˆë¬´ ì‘ìŒ: {original_size} â†’ ({min_size}, {min_size})")
            image = image.resize((min_size, min_size), Image.LANCZOS)
        
        logger.debug(f"âœ… ì´ë¯¸ì§€ ê²€ì¦ ì™„ë£Œ: í¬ê¸°={image.size}, ëª¨ë“œ={image.mode}")
        return image

    def predict_places(self, image_data_dict: dict, top_k=3) -> dict:
        """ì¥ì†Œ íƒœê¹… (ë°°ì¹˜ ì²˜ë¦¬)"""
        results = {}
        total_images = len(image_data_dict)
        processed_count = 0
        error_count = 0
        
        logger.info(f"ğŸš€ ì¥ì†Œ íƒœê¹… ì‹œì‘: ì´ {total_images}ê°œ ì´ë¯¸ì§€")
        batch_start_time = time.time()

        for image_url, image in image_data_dict.items():
            try:
                processed_count += 1
                logger.info(f"ğŸ” [{processed_count}/{total_images}] ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘: {image_url}")
                image_start_time = time.time()

                # ì´ë¯¸ì§€ ê²€ì¦ ë° ì „ì²˜ë¦¬
                image = self._validate_image(image)
                
                # CLIP ì…ë ¥ ì¤€ë¹„ ë¶€ë¶„ ìˆ˜ì •
                try:
                    # ì´ë¯¸ì§€ ë³€í™˜ ìˆ˜ì •
                    image_transforms = []
                    transforms = [
                        lambda x: x,  # ì›ë³¸
                        lambda x: x.transpose(Image.FLIP_LEFT_RIGHT)  # ì¢Œìš° ë°˜ì „
                    ]
                    
                    for transform in transforms:
                        processed = self.preprocess(transform(image))
                        image_transforms.append(processed)
                    
                    # í…ì„œ ìŠ¤íƒ ìˆ˜ì • (ë°°ì¹˜ ì°¨ì› ì˜¬ë°”ë¥´ê²Œ ì²˜ë¦¬)
                    image_tensors = torch.cat([t.unsqueeze(0) for t in image_transforms], dim=0).to(self.device)
                    
                    # í…ì„œ shape ë¡œê¹… ì¶”ê°€
                    logger.debug(f"ì´ë¯¸ì§€ í…ì„œ shape: {image_tensors.shape}")
                    
                    text_inputs = clip.tokenize(self.labels).to(self.device)

                    # ì˜ˆì¸¡ ìˆ˜í–‰
                    with torch.no_grad():
                        # ì´ë¯¸ì§€ íŠ¹ì§• ì¶”ì¶œ
                        image_features = self.model.encode_image(image_tensors)
                        text_features = self.model.encode_text(text_inputs)
                        
                        # ìœ ì‚¬ë„ ê³„ì‚°
                        similarity = F.softmax(
                            (image_features @ text_features.T).mean(dim=0).unsqueeze(0), 
                            dim=-1
                        )

                        # ìƒìœ„ ê²°ê³¼ ì¶”ì¶œ
                        best_match_indices = similarity.argsort(descending=True)[0][:top_k]
                        best_places = [
                            (self.labels[idx], float(similarity[0, idx].item()))
                            for idx in best_match_indices
                        ]
                        
                        # ì„ê³„ê°’ ê¸°ë°˜ í•„í„°ë§
                        valid_places = [
                            place for place in best_places 
                            if place[1] >= self.threshold
                        ]

                        # ê²°ê³¼ ì €ì¥
                        if valid_places:
                            place_name = valid_places[0][0].replace("a photo of ", "")
                            results[image_url] = {
                                "place": places.get(place_name, place_name),
                                "confidence": valid_places[0][1],
                                "all_predictions": [
                                    {"place": p[0], "confidence": p[1]} 
                                    for p in best_places[:3]
                                ]
                            }
                            
                            process_time = time.time() - image_start_time
                            # ìƒì„¸ ë¡œê¹… ì¶”ê°€
                            logger.info(
                                f"âœ… íƒœê¹… ì™„ë£Œ: {image_url}\n"
                                f"   - ìµœì¢… ì„ íƒ ì¥ì†Œ: {results[image_url]['place']} (ì‹ ë¢°ë„: {results[image_url]['confidence']:.4f})\n"
                                f"   - ìƒìœ„ 3ê°œ í›„ë³´:\n" + 
                                "\n".join([
                                    f"     {i+1}. {p[0].replace('a photo of ', '')} "  # outdoor scene ì œê±°
                                    f"(ì‹ ë¢°ë„: {p[1]:.4f})"
                                    for i, p in enumerate(best_places[:3])
                                ]) + f"\n"
                                f"   - ì²˜ë¦¬ì‹œê°„: {process_time:.2f}ì´ˆ"
                            )
                        else:
                            error_count += 1
                            results[image_url] = {
                                "error": "ì„ê³„ê°’ì„ ë„˜ëŠ” ì¥ì†Œê°€ ì—†ìŒ",
                                "best_guess": best_places[0] if best_places else None
                            }
                            # ì„ê³„ê°’ì„ ë„˜ì§€ ëª»í•œ ê²½ìš°ì—ë„ ìƒìœ„ í›„ë³´ ë¡œê¹…
                            logger.warning(
                                f"âš ï¸ ìœ íš¨í•œ ì¥ì†Œ ì—†ìŒ: {image_url}\n" +
                                "   - ìƒìœ„ 3ê°œ í›„ë³´ (ì„ê³„ê°’ {self.threshold} ë¯¸ë§Œ):\n" +
                                "\n".join([
                                    f"     {i+1}. {p[0].replace('a photo of ', '')} "  # outdoor scene ì œê±°
                                    f"(ì‹ ë¢°ë„: {p[1]:.4f})"
                                    for i, p in enumerate(best_places[:3])
                                ])
                            )

                except Exception as e:
                    error_count += 1
                    results[image_url] = {"error": str(e)}
                    logger.error(f"âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {image_url}", exc_info=True)

            except Exception as e:
                error_count += 1
                results[image_url] = {"error": str(e)}
                logger.error(f"âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {image_url}", exc_info=True)

        # ìµœì¢… í†µê³„
        total_time = time.time() - batch_start_time
        success_rate = ((total_images - error_count) / total_images) * 100
        
        logger.info(
            f"\nğŸ“Š ì²˜ë¦¬ ì™„ë£Œ í†µê³„:\n"
            f"   - ì´ ì´ë¯¸ì§€: {total_images}ê°œ\n"
            f"   - ì„±ê³µ: {total_images - error_count}ê°œ\n"
            f"   - ì‹¤íŒ¨: {error_count}ê°œ\n"
            f"   - ì„±ê³µë¥ : {success_rate:.1f}%\n"
            f"   - ì´ ì†Œìš”ì‹œê°„: {total_time:.2f}ì´ˆ\n"
            f"   - ì´ë¯¸ì§€ë‹¹ í‰ê·  ì²˜ë¦¬ì‹œê°„: {total_time/total_images:.2f}ì´ˆ"
        )

        return results