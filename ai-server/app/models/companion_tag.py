import json
import os
import numpy as np
import cv2
from deepface import DeepFace
from scipy.spatial.distance import cosine
from scipy.cluster.hierarchy import fcluster, linkage
from typing import Dict, List
from PIL import Image
import tempfile
import tensorflow as tf

# Metal í”ŒëŸ¬ê·¸ì¸ í™œì„±í™” ì‹œë„
try:
    tf.config.experimental.set_visible_devices([], 'GPU')
    print("âœ… TensorFlow Metal í”ŒëŸ¬ê·¸ì¸ í™œì„±í™”ë¨")
except:
    print("âš ï¸ TensorFlow Metal í”ŒëŸ¬ê·¸ì¸ í™œì„±í™” ì‹¤íŒ¨")

# âœ… í˜„ì¬ íŒŒì¼(companion_tag.py)ì˜ ê²½ë¡œë¥¼ ê¸°ì¤€ìœ¼ë¡œ `data/face_database.json` ì ˆëŒ€ ê²½ë¡œ ì„¤ì •
BASE_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))  # ai-server ê²½ë¡œ
DATABASE_PATH = os.path.join(BASE_DIR, "data", "face_database.json")  # ai-server/data/face_database.json

class CompanionTagger:
    def __init__(self):
        """ğŸ”¹ AI ì„œë²„ ë‚´ë¶€ ì €ì¥ëœ ì–¼êµ´ ë°ì´í„°ë² ì´ìŠ¤ ë¡œë“œ"""
        self.face_database = self.load_database()

    def load_database(self):
        """ğŸ”¹ AI ì„œë²„ ë‚´ë¶€ ì–¼êµ´ ë°ì´í„°ë² ì´ìŠ¤ ë¡œë“œ"""
        if os.path.exists(DATABASE_PATH):
            with open(DATABASE_PATH, "r", encoding="utf-8") as f:
                try:
                    return json.load(f)
                except json.JSONDecodeError:
                    print("âš ï¸ ë°ì´í„°ë² ì´ìŠ¤ JSON ë¡œë“œ ì‹¤íŒ¨ â†’ ì´ˆê¸°í™” ì§„í–‰")
                    return {}  # JSON ì˜¤ë¥˜ ë°œìƒ ì‹œ ì´ˆê¸°í™”
        return {}

    def save_database(self, database):
        """ğŸ”¹ AI ì„œë²„ ë‚´ë¶€ ì–¼êµ´ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥"""
        # person_idë¥¼ ìˆ«ì ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
        sorted_database = {}
        person_ids = sorted(database.keys(), key=lambda x: int(x.split('_')[1]))
        
        # 1ë²ˆë¶€í„° ìˆœì°¨ì ìœ¼ë¡œ ì¬í• ë‹¹
        for new_id, old_id in enumerate(person_ids, 1):
            sorted_database[f"person_{new_id}"] = database[old_id]
        
        # ì •ë ¬ëœ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
        os.makedirs(os.path.dirname(DATABASE_PATH), exist_ok=True)
        with open(DATABASE_PATH, "w", encoding="utf-8") as f:
            json.dump(sorted_database, f, ensure_ascii=False, indent=4)

    def get_face_embeddings(self, image_data_dict: Dict[str, Image.Image]):
        """ğŸ”¹ ì´ë¯¸ì§€ì—ì„œ ì–¼êµ´ ê²€ì¶œ ë° ì„ë² ë”© ì¶”ì¶œ"""
        face_data = []
        
        for url, img in image_data_dict.items():
            try:
                if not isinstance(img, Image.Image):
                    continue
                
                # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
                if img.mode != 'RGB':
                    img = img.convert('RGB')
                
                print(f"ğŸ” ì´ë¯¸ì§€ ì •ë³´: {url}")
                print(f"- í¬ê¸°: {img.size}")
                print(f"- ëª¨ë“œ: {img.mode}")
                print(f"- í˜•ì‹: {img.format}")
                
                with tempfile.NamedTemporaryFile(suffix='.jpg') as temp:
                    img.save(temp.name, 'JPEG', quality=95)
                    
                    try:
                        # ì–¼êµ´ ê²€ì¶œ - detector_kwargs ì œê±°
                        faces = DeepFace.extract_faces(
                            img_path=temp.name,
                            detector_backend='retinaface',
                            enforce_detection=True,
                            align=True
                        )
                        
                        if not faces:
                            print(f"âš ï¸ ì–¼êµ´ ê²€ì¶œ ì‹¤íŒ¨: {url}")
                            continue
                        
                        print(f"ğŸ” ê²€ì¶œëœ ì–¼êµ´ ìˆ˜: {len(faces)}")
                        
                        # ì„ë² ë”© ì¶”ì¶œ - enforce_detection=Trueë¡œ ë³€ê²½
                        embeddings = DeepFace.represent(
                            img_path=temp.name,
                            model_name="Facenet",
                            enforce_detection=True,  # False â†’ True
                            detector_backend='retinaface'
                        )
                        
                        if not isinstance(embeddings, list):
                            embeddings = [embeddings]
                        
                        for i, embedding in enumerate(embeddings):
                            if isinstance(embedding, dict) and 'embedding' in embedding:
                                embedding_array = np.array(embedding['embedding'])
                            else:
                                embedding_array = np.array(embedding)
                            
                            if embedding_array.shape == (128,):
                                face_data.append((url, embedding_array))
                                print(f"âœ… ì–¼êµ´ {i+1} ì„ë² ë”© ì¶”ì¶œ ì™„ë£Œ: {url}")
                
                    except Exception as e:
                        print(f"âš ï¸ ì–¼êµ´ ê²€ì¶œ/ì„ë² ë”© ì¶”ì¶œ ì‹¤íŒ¨: {url}, ì˜¤ë¥˜: {str(e)}")
                        continue
                    
            except Exception as e:
                print(f"âš ï¸ ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨: {url}, ì˜¤ë¥˜: {str(e)}")
                continue
        
        return face_data

    def cluster_faces_hierarchical(self, face_data, threshold=0.7):
        """ğŸ”¹ ë°°ì¹˜ ë‚´ ì–¼êµ´ í´ëŸ¬ìŠ¤í„°ë§"""
        if not face_data:
            return {}
        
        embeddings = np.array([data[1] for data in face_data if data[1] is not None])
        
        if len(embeddings) < 2:
            return {data[0]: ["person_1"] for data in face_data}

        # ìœ ì‚¬ë„ í–‰ë ¬ ê³„ì‚° (ì½”ì‚¬ì¸ ê±°ë¦¬ ëŒ€ì‹  1 - ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ì‚¬ìš©)
        similarity_matrix = np.zeros((len(embeddings), len(embeddings)))
        for i in range(len(embeddings)):
            for j in range(i + 1, len(embeddings)):
                similarity = 1 - cosine(embeddings[i], embeddings[j])
                similarity_matrix[i][j] = 1 - similarity  # ìœ ì‚¬ë„ë¥¼ ê±°ë¦¬ë¡œ ë³€í™˜
                similarity_matrix[j][i] = 1 - similarity

        # ê³„ì¸µì  í´ëŸ¬ìŠ¤í„°ë§ ìˆ˜í–‰
        linkage_matrix = linkage(similarity_matrix, method='complete')
        clusters = fcluster(linkage_matrix, 1 - threshold, criterion='distance')  # threshold ê¸°ì¤€ ë°˜ì „
        
        # ê²°ê³¼ ë§¤í•‘
        result = {url: [] for url, _ in face_data}
        for i, cluster_id in enumerate(clusters):
            url = face_data[i][0]
            result[url].append(f"person_{cluster_id}")
            print(f"ğŸ” {url} â†’ í´ëŸ¬ìŠ¤í„° {cluster_id} (ìœ ì‚¬ë„: {1 - similarity_matrix[i][i-1]:.3f})")
        
        return result

    def match_with_database(self, assigned_tags, face_data, threshold=0.6):
        '''í´ëŸ¬ìŠ¤í„°ë§ëœ ì–¼êµ´ì„ DBì™€ ë§¤ì¹­'''
        result = {}
        
        # ë°ì´í„°ë² ì´ìŠ¤ ë¡œë“œ
        database = self.load_database()
        
        for image_url in assigned_tags.keys():
            result[image_url] = []
            
            # ì´ë¯¸ì§€ì—ì„œ ê²€ì¶œëœ ì–¼êµ´ë“¤ì˜ ì„ë² ë”© ì°¾ê¸°
            image_embeddings = [emb for url, emb in face_data if url == image_url]
            print(f"- ì´ë¯¸ì§€ {image_url}ì˜ ì„ë² ë”© ê°œìˆ˜: {len(image_embeddings)}")
            
            # DBê°€ ë¹„ì–´ìˆê±°ë‚˜ ë°©ê¸ˆ ìƒì„±ëœ ê²½ìš°, í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ ì‚¬ìš©
            if not database or len(database) == len(image_embeddings):
                result[image_url] = assigned_tags[image_url]
                print(f"âœ… ìƒˆë¡œìš´ ì¸ë¬¼ íƒœê·¸ ìƒì„±: {assigned_tags[image_url]}")
                continue
            
            # ê° ì–¼êµ´ ì„ë² ë”©ì— ëŒ€í•´ ê¸°ì¡´ DBì™€ ë§¤ì¹­
            for embedding in image_embeddings:
                matched_person = None
                max_similarity = -1
                
                # DBì˜ ê° ì¸ë¬¼ê³¼ ë¹„êµ
                for person_id, person_data in database.items():
                    for db_data in person_data["embeddings"]:
                        db_embedding = db_data["embedding"]
                        similarity = 1 - cosine(embedding, db_embedding)
                        if similarity > max_similarity and similarity >= threshold:
                            max_similarity = similarity
                            matched_person = person_id
                
                # ë§¤ì¹­ëœ ì¸ë¬¼ì´ ìˆìœ¼ë©´ ê²°ê³¼ì— ì¶”ê°€
                if matched_person:
                    if matched_person not in result[image_url]:  # ì¤‘ë³µ ë°©ì§€
                        result[image_url].append(matched_person)
                        print(f"âœ… ë§¤ì¹­ëœ ì¸ë¬¼ ì¶”ê°€: {image_url} â†’ {matched_person} (ìœ ì‚¬ë„: {max_similarity:.3f})")
                else:
                    print(f"âš ï¸ ë§¤ì¹­ëœ ì¸ë¬¼ ì—†ìŒ: ìµœëŒ€ ìœ ì‚¬ë„ {max_similarity:.3f}")
        
        return result

    def process_faces(self, image_data_dict: Dict[str, Image.Image]):
        """ğŸ”¹ ì¸ë¬¼ íƒœê¹… ì‹¤í–‰ í•¨ìˆ˜ (ì—¬ëŸ¬ ì–¼êµ´ ì²˜ë¦¬)"""
        face_dir = "data/faces"
        os.makedirs(face_dir, exist_ok=True)
        
        # ì–¼êµ´ ê²€ì¶œ ë° ì„ë² ë”© ì¶”ì¶œ
        face_data = self.get_face_embeddings(image_data_dict)
        face_images = self.get_face_images(image_data_dict)
        print(f"ğŸ” ê²€ì¶œëœ ì–¼êµ´ ë°ì´í„°: {len(face_data)}ê°œ")
        
        # ì–¼êµ´ì´ ê²€ì¶œë˜ì§€ ì•Šì€ ê²½ìš° ë¹ˆ ê²°ê³¼ ë°˜í™˜
        if not face_data:
            print("âš ï¸ ê²€ì¶œëœ ì–¼êµ´ ì—†ìŒ")
            return {url: [] for url in image_data_dict.keys()}
        
        # 1. ë°°ì¹˜ ë‚´ ì–¼êµ´ í´ëŸ¬ìŠ¤í„°ë§ ìˆ˜í–‰
        batch_clusters = self.cluster_faces_hierarchical(face_data, threshold=0.7)
        print(f"âœ… ë°°ì¹˜ ë‚´ í´ëŸ¬ìŠ¤í„°ë§ ì™„ë£Œ: {len(batch_clusters)}ê°œ ì´ë¯¸ì§€")
        
        # 2. DB ë¡œë“œ ë° ë§¤ì¹­
        database = self.load_database()
        if not database:
            print("âœ… DB ì—†ìŒ â†’ í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ë¡œ ìƒˆ DB ìƒì„±")
            
            # í´ëŸ¬ìŠ¤í„°ë³„ ì–¼êµ´ ë§¤í•‘ ë° ì„ë² ë”© ë§¤í•‘
            cluster_faces = {}
            cluster_embeddings = {}  # í´ëŸ¬ìŠ¤í„°ë³„ ì„ë² ë”© ì €ì¥
            
            # ì–¼êµ´ê³¼ ì„ë² ë”©ì„ í´ëŸ¬ìŠ¤í„°ë³„ë¡œ ë§¤í•‘
            for url, faces in face_images.items():
                clusters = batch_clusters[url]
                # í•´ë‹¹ URLì˜ ì„ë² ë”© ì°¾ê¸°
                url_embeddings = [emb for f_url, emb in face_data if f_url == url]
                
                for i, (face, cluster_id, embedding) in enumerate(zip(faces, clusters, url_embeddings)):
                    person_id = f"person_{cluster_id.split('_')[1]}"
                    
                    # ì–¼êµ´ ì´ë¯¸ì§€ ì €ì¥ (ì²˜ìŒ í•œ ë²ˆë§Œ)
                    if person_id not in cluster_faces:
                        cluster_faces[person_id] = face
                        face_path = os.path.join(face_dir, f"{person_id}.jpg")
                        face.save(face_path)
                        print(f"âœ… ì–¼êµ´ ì´ë¯¸ì§€ ì €ì¥: {face_path}")
                    
                    # ì„ë² ë”© ë§¤í•‘
                    if person_id not in cluster_embeddings:
                        cluster_embeddings[person_id] = []
                    cluster_embeddings[person_id].append({
                        "url": url,
                        "embedding": embedding.tolist()
                    })
            
            # DB ìƒì„±
            for person_id, embeddings in cluster_embeddings.items():
                database[person_id] = {
                    "embeddings": embeddings
                }
                print(f"âœ… {person_id}ì˜ ì„ë² ë”© {len(embeddings)}ê°œ ì €ì¥")
            self.save_database(database)
            return batch_clusters
        
        # 3. ê¸°ì¡´ DBê°€ ìˆëŠ” ê²½ìš°, ê° í´ëŸ¬ìŠ¤í„°ì™€ DB ë§¤ì¹­
        print("âœ… ê¸°ì¡´ DBì™€ ë§¤ì¹­ ì‹œë„")
        final_results = {url: [] for url in image_data_dict.keys()}
        db_updates = {}  # DB ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•œ ì„ì‹œ ì €ì¥ì†Œ
        
        face_idx = {}
        for url in image_data_dict.keys():
            face_idx[url] = 0
        
        for url, cluster_ids in batch_clusters.items():
            for cluster_id in cluster_ids:
                # í•´ë‹¹ í´ëŸ¬ìŠ¤í„°ì˜ ëŒ€í‘œ ì„ë² ë”© ì°¾ê¸°
                cluster_embedding = None
                current_face_idx = face_idx[url]
                for i, (face_url, embedding) in enumerate(face_data):
                    if face_url == url and i == current_face_idx:  # í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ ì–¼êµ´ì˜ ì„ë² ë”©ì„ ì •í™•íˆ ì°¾ìŒ
                        cluster_embedding = embedding
                        break
                
                if cluster_embedding is None:
                    continue
                
                # DBì˜ ê° ì¸ë¬¼ê³¼ ë¹„êµ
                best_match = None
                max_similarity = -1
                
                for person_id, person_data in database.items():
                    for db_data in person_data["embeddings"]:
                        similarity = 1 - cosine(cluster_embedding, np.array(db_data["embedding"]))
                        print(f"- ìœ ì‚¬ë„ ì²´í¬: {cluster_id} vs {person_id} â†’ {similarity:.3f}")
                        if similarity > max_similarity:
                            max_similarity = similarity
                            if similarity >= 0.55:  # 0.6 â†’ 0.55ë¡œ ì„ê³„ê°’ ë‚®ì¶¤
                                best_match = person_id
                            print(f"  â†’ max_similarity ê°±ì‹ : {similarity:.3f}")
                            if best_match:
                                print(f"  â†’ best_match ê°±ì‹ : {best_match}")
                
                print(f"ìµœì¢… best_match: {best_match}, max_similarity: {max_similarity:.3f}")

                if best_match:
                    print(f"âœ… if best_match ì¡°ê±´ë¬¸ ì§„ì…")
                    # DBì˜ ê¸°ì¡´ ì¸ë¬¼ê³¼ ë§¤ì¹­ëœ ê²½ìš°
                    print(f"âœ… í´ëŸ¬ìŠ¤í„° {cluster_id} â†’ DBì˜ {best_match}ì™€ ë§¤ì¹­ (ìœ ì‚¬ë„: {max_similarity:.3f})")
                    if best_match not in final_results[url]:
                        final_results[url].append(best_match)
                    # ìƒˆ ì„ë² ë”© ì„ì‹œ ì €ì¥
                    if best_match not in db_updates:
                        db_updates[best_match] = []
                    db_updates[best_match].append({
                        "url": url,
                        "embedding": cluster_embedding.tolist()
                    })
                    face_idx[url] += 1
                else:
                    print(f"âŒ best_matchê°€ Noneì´ì–´ì„œ ìƒˆ ì¸ë¬¼ ì¶”ê°€")
                    # ìƒˆë¡œìš´ ì¸ë¬¼ë¡œ ì¶”ê°€
                    next_id = max([int(pid.split('_')[1]) for pid in list(database.keys()) + list(db_updates.keys())]) + 1
                    new_person_id = f"person_{next_id}"
                    print(f"âœ… ìƒˆë¡œìš´ ì¸ë¬¼ ì¶”ê°€: {new_person_id}")
                    
                    # ìƒˆ ì¸ë¬¼ì˜ ì–¼êµ´ ì´ë¯¸ì§€ ì €ì¥
                    if url in face_images:
                        face_path = os.path.join(face_dir, f"{new_person_id}.jpg")
                        face_img = face_images[url][face_idx[url]]
                        face_img.save(face_path)
                        print(f"âœ… ì–¼êµ´ ì´ë¯¸ì§€ ì €ì¥: {face_path}")

                    if new_person_id not in db_updates:
                        db_updates[new_person_id] = []
                    db_updates[new_person_id].append({
                        "url": url,
                        "embedding": cluster_embedding.tolist()
                    })
                    face_idx[url] += 1
                    final_results[url].append(new_person_id)
        
        # ëª¨ë“  ë§¤ì¹­ì´ ëë‚œ í›„ DB ì—…ë°ì´íŠ¸
        if db_updates:
            for person_id, embeddings in db_updates.items():
                if person_id in database:
                    database[person_id]["embeddings"].extend(embeddings)
                else:
                    database[person_id] = {"embeddings": embeddings}
            self.save_database(database)
            print("âœ… DB ì €ì¥ ì™„ë£Œ")
        
        # ê²°ê³¼ ë°˜í™˜ ì „ì— ì¸ë¬¼ íƒœê·¸ ì •ë ¬
        for url in final_results:
            final_results[url] = sorted(final_results[url], key=lambda x: int(x.split('_')[1]))
        
        return final_results

    def get_face_images(self, image_data_dict: Dict[str, Image.Image]):
        """ğŸ”¹ ì–¼êµ´ ì´ë¯¸ì§€ ì¶”ì¶œ"""
        face_images = {}
        
        for url, img in image_data_dict.items():
            try:
                if not isinstance(img, Image.Image):
                    continue
                
                # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
                if img.mode != 'RGB':
                    img = img.convert('RGB')
                
                with tempfile.NamedTemporaryFile(suffix='.jpg') as temp:
                    img.save(temp.name, 'JPEG', quality=95)
                    
                    # ì–¼êµ´ ê²€ì¶œ
                    try:
                        faces = DeepFace.extract_faces(
                            img_path=temp.name,
                            detector_backend='retinaface',
                            enforce_detection=True,  # ì–¼êµ´ ê²€ì¶œ ê°•ì œ
                            align=True
                        )
                        
                        # ì–¼êµ´ì´ ê²€ì¶œëœ ê²½ìš°ì—ë§Œ ì²˜ë¦¬
                        if faces and len(faces) > 0:
                            face_images[url] = []
                            for face in faces:
                                if 'face' in face and face['face'] is not None:
                                    face_array = face['face']
                                    if isinstance(face_array, np.ndarray):
                                        if face_array.dtype != np.uint8:
                                            face_array = (face_array * 255).astype(np.uint8)
                                        if len(face_array.shape) == 2:
                                            face_array = cv2.cvtColor(face_array, cv2.COLOR_GRAY2RGB)
                                        elif face_array.shape[-1] == 4:
                                            face_array = cv2.cvtColor(face_array, cv2.COLOR_RGBA2RGB)
                                        
                                        face_img = Image.fromarray(face_array)
                                        face_img = face_img.resize((224, 224), Image.Resampling.LANCZOS)
                                        face_images[url].append(face_img)
                                        print(f"âœ… ì–¼êµ´ ì´ë¯¸ì§€ ì¶”ì¶œ ì„±ê³µ: {url} (ì–¼êµ´ {len(face_images[url])})")
                        else:
                            print(f"âš ï¸ ì–¼êµ´ ê²€ì¶œ ì‹¤íŒ¨: {url}")
                    
                    except Exception as e:
                        print(f"âš ï¸ ì–¼êµ´ ê²€ì¶œ ì‹¤íŒ¨: {url}, ì˜¤ë¥˜: {str(e)}")
                        continue
            
            except Exception as e:
                print(f"âš ï¸ ì–¼êµ´ ì´ë¯¸ì§€ ì¶”ì¶œ ì‹¤íŒ¨: {url}, ì˜¤ë¥˜: {str(e)}")
                continue
        
        return face_images